{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to spaCy/DaCy and Named Entity Recognition (NER)\n",
    "This notebook is an introduction to the spaCy/DaCy universe, and will introduce some of its basic functionality such as  extracting named entities (e.g. people, places, locations) from text.\n",
    "\n",
    "In this notebook we will focus on small examples, but the methods carry over to the data that we have prepared for you on UCloud. \n",
    "\n",
    "This notebook is mainly meant as a reference to consult when working on the next task. Read through it, run the code, and try to think of ways these methods might be useful for gaining insights from the web/Twitter data. The next notebook contains exercises specific to your data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why NER?\n",
    "\n",
    "Named Entity Recognition (NER) is the task of identifying named entities in a text. A named entity is a “real-world object” that’s assigned a name - for example, a person, a country, a product or a book title.\n",
    "NER is extremely usable for a wide range of tasks:\n",
    "1. Anonymising documents (replacing named entities with a pseudonym)\n",
    "2. Information extraction: finding important actors/entities within a document. This could be used to e.g. automatically link to an employee's profile or to create location tags.\n",
    "3. Categorizing documents based on the occurence of certain entities\n",
    "\n",
    "## NER in Danish\n",
    "\n",
    "There are multiple tools for Danish NER. The fastest uses the [spaCy](https://spacy.io/) library, and the most accurate uses [DaCy](https://github.com/centre-for-humanities-computing/DaCy), which was developed here at CHC.\n",
    "\n",
    "\n",
    "### Getting started\n",
    "\n",
    "First off, we need to import the libraries that we intend to use. Let's load spaCy and DaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dacy\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the language models, we have to load them. Let's see an example with spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a Danish spacy model\n",
    "nlp = spacy.load(\"da_core_news_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model is as simple as supplying a text to the `nlp` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Joe Biden omtalte Kinas præsident som diktator: 'Nu kommer den rigtige test af, om de vil forbedre forholdet'\" \n",
    "doc = nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use spaCy/daCy to analyse the text. For instance, we can look at the individual sentences in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden omtalte Kinas præsident som diktator: '\n",
      "Nu kommer den rigtige test af, om de vil forbedre forholdet'\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or find the named entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden PER\n",
      "Kinas LOC\n"
     ]
    }
   ],
   "source": [
    "for named_entity in doc.ents:\n",
    "    print(named_entity.text, named_entity.label_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the named entities using the built-in visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joe Biden\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " omtalte \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kinas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " præsident som diktator: 'Nu kommer den rigtige test af, om de vil forbedre forholdet'</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained NER with DaCy\n",
    "While the model for named entity recognition in spaCy is fast, it's limited to only people (PER), locations (LOC), and organizations (ORG). The DaCy model allows us to look at more fine-grained entities as illustrated in the table below:\n",
    "\n",
    "|  Tag        |             Description                                         | \n",
    "| -------- | ---------------------------------------------------- | \n",
    "| PERSON   | People, including fictional                          | \n",
    "| NORP     | Nationalities or religious or political groups       | \n",
    "| FACILITY | Building, airports, highways, bridges, etc.          | \n",
    "| ORGANIZATION | Companies, agencies, institutions, etc.              | \n",
    "| GPE      | Countries, cities, states.                           | \n",
    "| LOCATION | Non-GPE locations, mountain ranges, bodies of water  | \n",
    "| PRODUCT  | Vehicles, weapons, foods, etc. (not services)        | \n",
    "| EVENT    | Named hurricanes, battles, wars, sports events, etc. | \n",
    "| WORK OF ART | Titles of books, songs, etc.                         | \n",
    "| LAW      | Named documents made into laws                       | \n",
    "| LANGUAGE | Any named language                                   | \n",
    "     \n",
    "As well as annotations for the following concepts: \n",
    "\n",
    "\n",
    "|   Tag       |   Description                                         | \n",
    "| -------- | ------------------------------------------- | \n",
    "| DATE     | Absolute or relative dates or periods       | \n",
    "| TIME     | Times smaller than a day                    | \n",
    "| PERCENT  | Percentage (including '\\*'\\%)                | \n",
    "| MONEY    | Monetary values, including unit             | \n",
    "| QUANTITY | Measurements, as of weight or distance      | \n",
    "| ORDINAL  | \"first\", \"second\"                           | \n",
    "| CARDINAL | Numerals that do no fall under another type | \n",
    "\n",
    "\n",
    "Let's try to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting da-dacy-small-trf==any\n",
      "  Downloading https://huggingface.co/chcaa/da_dacy_small_trf/resolve/0eadea074d5f637e76357c46bbd56451471d0154/da_dacy_small_trf-any-py3-none-any.whl (101.3 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.3/101.3 MB 16.9 MB/s eta 0:00:00\n",
      "\u001b[?25hInstalling collected packages: da-dacy-small-trf\n",
      "Successfully installed da-dacy-small-trf-0.2.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting da-dacy-small-ner-fine-grained==any\n",
      "  Downloading https://huggingface.co/chcaa/da_dacy_small_ner_fine_grained/resolve/43fedc5a1b1c1d193f461d13225f217f2ced507d/da_dacy_small_ner_fine_grained-any-py3-none-any.whl (82.7 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.7/82.7 MB 21.5 MB/s eta 0:00:00\n",
      "\u001b[?25hInstalling collected packages: da-dacy-small-ner-fine-grained\n",
      "Successfully installed da-dacy-small-ner-fine-grained-0.1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.ner.EntityRecognizer at 0x7f3b6b18f990>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the small dacy model excluding the NER component\n",
    "dacy_nlp = dacy.load(\"small\", exclude=[\"ner\"])\n",
    "\n",
    "# add the ner component from the fine-grained model\n",
    "dacy_nlp.add_pipe(\"dacy/ner-fine-grained\", config={\"size\": \"small\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Denne model samt \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " andre blev trænet \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    d. 7. marts\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " af \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Center for Humantities Computing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORGANIZATION</span>\n",
       "</mark>\n",
       " i \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Aarhus kommune\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = dacy_nlp(\"Denne model samt 3 andre blev trænet d. 7. marts af Center for Humantities Computing i Aarhus kommune\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running spaCy/DaCy on multiple texts\n",
    "To analyze multiple texts at once, you can use the `nlp.pipe` method. Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Her er det \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " tekststykke. Det er kort, og uden personer.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First document!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Her er det \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " tekststykke. Det er lidt længere, og indeholder en person. Vi kunne kalde ham \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kristoffer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Her er det 1. tekststykke. Det er kort, og uden personer.\",\n",
    "    \"Her er det 2. tekststykke. Det er lidt længere, og indeholder en person. Vi kunne kalde ham Kristoffer.\",\n",
    "]\n",
    "\n",
    "docs = dacy_nlp.pipe(texts)\n",
    "# iterate over the documents one by one\n",
    "for doc in docs:\n",
    "    print(\"First document!\")\n",
    "    displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemmatization is the act of grouping together the inflected forms of a word so they can be analysed as a single item. For example, the verb “to run” has the base form “run”, and the verb “ran” has the base form “run”.\n",
    "\n",
    "Lemmatization is for example used for text normalization before training a machine learning model to reduce the number of unique tokens in the training data. Let's see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisering Normalisering\n",
      "af af\n",
      "tekst tekst\n",
      "kan kunne\n",
      "være være\n",
      "en en\n",
      "god god\n",
      "idé idé\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Normalisering af tekst kan være en god idé.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.lemma_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other linguistic features\n",
    "\n",
    "SpaCy/DaCy is not limited to extracting NER or doing lemmatization. You can perform many complex linguistic analysis, such as investigating part-of-speech tags, or the dependency relations between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisering NOUN nsubj idé\n",
      "af ADP case tekst\n",
      "tekst NOUN nmod Normalisering\n",
      "kan AUX aux idé\n",
      "være AUX cop idé\n",
      "en DET det idé\n",
      "god ADJ amod idé\n",
      "idé NOUN ROOT idé\n",
      ". PUNCT punct idé\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples, check out the [DaCy tutorials](https://centre-for-humanities-computing.github.io/DaCy/tutorials.html) or the [spaCy 101](https://spacy.io/usage/spacy-101)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
